import os
import re
import httpx
import paramiko
import json
import yt_dlp
from urllib.parse import urlparse
from datetime import datetime

# è¨­ç½®æ—¥èªŒæª”æ¡ˆ
LOG_FILE = "parse.log"

def log_message(message):
    """è¨˜éŒ„æ—¥èªŒåˆ°æª”æ¡ˆ"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {message}\n")

yt_info_path = "yt_info.txt"
output_dir = "output"
cookies_path = os.path.join(os.getcwd(), "cookies.txt")
API_KEY = os.getenv("YT_API_KEY", "")
if not API_KEY:
    log_message("âŒ ç’°å¢ƒè®Šæ•¸ YT_API_KEY æœªè¨­ç½®ï¼Œæ”¹ç”¨ HTML è§£æ")

SF_L = os.getenv("SF_L", "")
if not SF_L:
    log_message("âŒ ç’°å¢ƒè®Šæ•¸ SF_L æœªè¨­ç½®")
    exit(1)

parsed_url = urlparse(SF_L)
SFTP_HOST = parsed_url.hostname
SFTP_PORT = parsed_url.port if parsed_url.port else 22
SFTP_USER = parsed_url.username
SFTP_PASSWORD = parsed_url.password
SFTP_REMOTE_DIR = parsed_url.path if parsed_url.path else "/"

os.makedirs(output_dir, exist_ok=True)

def get_channel_id(youtube_url):
    """å¾ YouTube URL æå–é »é“ IDï¼Œå„ªå…ˆä½¿ç”¨ API"""
    handle = youtube_url.split("/")[-2] if "/@" in youtube_url else None
    if API_KEY and handle:
        try:
            url = f"https://www.googleapis.com/youtube/v3/channels?part=id&forHandle={handle}&key={API_KEY}"
            with httpx.Client(timeout=15) as client:
                res = client.get(url)
                res.raise_for_status()
                data = res.json()
                if data.get("items"):
                    channel_id = data["items"][0]["id"]
                    log_message(f"âœ… API æ‰¾åˆ°é »é“ ID: {channel_id} for {youtube_url}")
                    return channel_id
                log_message(f"âš ï¸ API ç„¡æ³•æ‰¾åˆ° {handle} çš„é »é“ IDï¼Œå˜—è©¦ HTML è§£æ")
        except Exception as e:
            log_message(f"âš ï¸ API ç²å–é »é“ ID å¤±æ•— for {youtube_url}: {e}")

    # å›é€€åˆ° HTML è§£æ
    try:
        with httpx.Client(http2=True, follow_redirects=True, timeout=15) as client:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
                "Connection": "keep-alive"
            }
            res = client.get(youtube_url, headers=headers)
            html = res.text
            patterns = [
                r'"channelId":"(UC[^"]+)"',
                r'<meta itemprop="channelId" content="(UC[^"]+)"',
                r'"externalId":"(UC[^"]+)"'
            ]
            for pattern in patterns:
                match = re.search(pattern, html)
                if match:
                    channel_id = match.group(1)
                    log_message(f"âœ… HTML æ‰¾åˆ°é »é“ ID: {channel_id} for {youtube_url}")
                    return channel_id
            log_message(f"âš ï¸ ç„¡æ³•å¾ {youtube_url} æå–é »é“ ID")
            return None
    except Exception as e:
        log_message(f"âš ï¸ HTML æå–é »é“ ID å¤±æ•— for {youtube_url}: {e}")
        return None

def get_live_video_id(channel_id):
    """ä½¿ç”¨ YouTube Data API ç²å–ç›´æ’­ videoId"""
    try:
        url = f"https://www.googleapis.com/youtube/v3/search?part=snippet&channelId={channel_id}&eventType=live&type=video&key={API_KEY}"
        with httpx.Client(timeout=15) as client:
            res = client.get(url)
            res.raise_for_status()
            data = res.json()
            if data.get("items"):
                video_id = data["items"][0]["id"]["videoId"]
                log_message(f"âœ… æ‰¾åˆ°ç›´æ’­ videoId: {video_id} for channel {channel_id}")
                return f"https://www.youtube.com/watch?v={video_id}"
            log_message(f"âš ï¸ é »é“ {channel_id} ç›®å‰ç„¡ç›´æ’­ (API è¿”å›ç©ºçµæœ)")
            return None
    except Exception as e:
        log_message(f"âš ï¸ API è«‹æ±‚å¤±æ•— for channel {channel_id}: {e}")
        return None

def grab(youtube_url):
    """æŠ“å– m3u8 ç›´æ’­æµï¼Œå„ªå…ˆ HTML è§£æï¼Œå¤±æ•—å‰‡å›é€€åˆ° yt-dlp"""
    # æ–¹æ³• 1: HTML è§£æ
    log_message(f"ğŸ” å˜—è©¦ HTML è§£æ M3U8 for {youtube_url}")
    with httpx.Client(http2=True, follow_redirects=True, timeout=15) as client:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Connection": "keep-alive"
        }

        cookies = {}
        if os.path.exists(cookies_path):
            try:
                with open(cookies_path, "r", encoding="utf-8") as f:
                    for line in f:
                        if not line.startswith('#') and '\t' in line:
                            parts = line.strip().split('\t')
                            if len(parts) >= 6:
                                cookies[parts[5]] = parts[6]
                log_message(f"âœ… å·²è¼‰å…¥ Cookies for {youtube_url}")
            except Exception as e:
                log_message(f"âš ï¸ Cookie è®€å–å¤±æ•— for {youtube_url}: {e}")

        try:
            res = client.get(youtube_url, headers=headers, cookies=cookies)
            html = res.text

            if 'noindex' in html:
                log_message(f"âš ï¸ é »é“ {youtube_url} ç›®å‰æœªé–‹å•Ÿç›´æ’­ (HTML)")
                return None

            # å˜—è©¦å¾ player_response JSON ä¸­æå– m3u8
            player_response_match = re.search(r'ytInitialPlayerResponse\s*=\s*({.*?});', html, re.DOTALL)
            if player_response_match:
                player_response = json.loads(player_response_match.group(1))
                streaming_data = player_response.get("streamingData", {})
                hls_formats = streaming_data.get("hlsManifestUrl", "")
                if hls_formats:
                    log_message(f"âœ… HTML è§£ææˆåŠŸï¼Œæ‰¾åˆ° .m3u8 é€£çµ: {hls_formats} for {youtube_url}")
                    return hls_formats

            # å‚™ç”¨æ­£å‰‡è¡¨é”å¼
            m3u8_matches = re.findall(r'(https://[^"]+\.m3u8[^"]*)', html)
            for url in m3u8_matches:
                if "googlevideo.com" in url:
                    log_message(f"âœ… HTML è§£ææˆåŠŸï¼ˆæ­£å‰‡ï¼‰ï¼Œæ‰¾åˆ° .m3u8 é€£çµ: {url} for {youtube_url}")
                    return url

            log_message(f"âš ï¸ HTML è§£ææœªæ‰¾åˆ°æœ‰æ•ˆçš„ .m3u8 é€£çµ for {youtube_url}")
        except Exception as e:
            log_message(f"âš ï¸ HTML è§£æå¤±æ•— for {youtube_url}: {e}")

    # æ–¹æ³• 2: yt-dlp è§£æ
    log_message(f"ğŸ”„ å›é€€åˆ° yt-dlp è§£æ M3U8 for {youtube_url}")
    try:
        ydl_opts = {
            'format': 'best',  # é¸æ“‡æœ€ä½³æ ¼å¼ï¼ˆé€šå¸¸åŒ…å« m3u8ï¼‰
            'cookiesfrombrowser': None,  # è‹¥ç„¡éœ€ Cookies å¯è¨­ç‚º None
            'quiet': True,  # æ¸›å°‘æ—¥èªŒè¼¸å‡º
            'no_warnings': True,  # éš±è—è­¦å‘Š
            'extract_flat': False,  # æå–å®Œæ•´è³‡è¨Š
            'force_generic_extractor': False,
        }

        # å¦‚æœå­˜åœ¨ Cookies æª”æ¡ˆï¼ŒåŠ å…¥ yt-dlp é¸é …
        if os.path.exists(cookies_path):
            ydl_opts['cookiefile'] = cookies_path

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)  # ä¸ä¸‹è¼‰ï¼Œåªæå–è³‡è¨Š
            if not info.get('is_live'):
                log_message(f"âš ï¸ {youtube_url} ç›®å‰ä¸æ˜¯ç›´æ’­ (yt-dlp)")
                return None
            hls_url = info.get('url')  # æå– m3u8 é€£çµ
            if hls_url and '.m3u8' in hls_url:
                log_message(f"âœ… yt-dlp è§£ææˆåŠŸï¼Œæ‰¾åˆ° .m3u8 é€£çµ: {hls_url} for {youtube_url}")
                return hls_url
            else:
                log_message(f"âš ï¸ yt-dlp æœªæ‰¾åˆ°æœ‰æ•ˆçš„ .m3u8 é€£çµ for {youtube_url}")
                return None
    except Exception as e:
        log_message(f"âš ï¸ yt-dlp è§£æå¤±æ•— for {youtube_url}: {e}")
        return None

def process_yt_info():
    with open(yt_info_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    i = 1
    for line in lines:
        line = line.strip()
        if line.startswith("~~") or not line:
            continue
        if "|" in line:
            parts = line.split("|")
            channel_name = parts[0].strip() if len(parts) > 0 else f"Channel {i}"
        else:
            youtube_url = line
            log_message(f"ğŸ” é–‹å§‹è™•ç†: {youtube_url}")

            # æå–é »é“ ID
            channel_id = get_channel_id(youtube_url)
            if not channel_id:
                log_message(f"âš ï¸ è·³é {youtube_url}ï¼Œç„¡æ³•ç²å–é »é“ ID")
                continue

            # ä½¿ç”¨ API ç²å–ç›´æ’­ URL
            if API_KEY:
                live_url = get_live_video_id(channel_id)
                if not live_url:
                    log_message(f"âš ï¸ é »é“ {youtube_url} ç„¡ç›´æ’­ï¼Œè·³é")
                    continue
            else:
                live_url = youtube_url  # ç„¡ API é‡‘é‘°æ™‚å›é€€åˆ°åŸå§‹ URL

            # æŠ“å– m3u8
            m3u8_url = grab(live_url)
            if m3u8_url is None:
                m3u8_url = "https://raw.githubusercontent.com/jz168k/YT2m/main/assets/no_s.m3u8"
                log_message(f"âš ï¸ ä½¿ç”¨é è¨­ .m3u8 é€£çµ: {m3u8_url} for {youtube_url}")

            m3u8_content = f"#EXTM3U\n#EXT-X-STREAM-INF:BANDWIDTH=1280000\n{m3u8_url}\n"
            output_m3u8 = os.path.join(output_dir, f"y{i:02d}.m3u8")
            with open(output_m3u8, "w", encoding="utf-8") as f:
                f.write(m3u8_content)

            php_content = f"""<?php
header('Location: {m3u8_url}');
?>"""
            output_php = os.path.join(output_dir, f"y{i:02d}.php")
            with open(output_php, "w", encoding="utf-8") as f:
                f.write(php_content)

            log_message(f"âœ… ç”Ÿæˆ {output_m3u8} å’Œ {output_php} for {youtube_url}")
            i += 1

def upload_files():
    log_message("ğŸš€ å•Ÿå‹• SFTP ä¸Šå‚³ç¨‹åº...")
    try:
        transport = paramiko.Transport((SFTP_HOST, SFTP_PORT))
        transport.connect(username=SFTP_USER, password=SFTP_PASSWORD)
        sftp = paramiko.SFTPClient.from_transport(transport)

        log_message(f"âœ… æˆåŠŸé€£æ¥åˆ° SFTPï¼š{SFTP_HOST}")

        try:
            sftp.chdir(SFTP_REMOTE_DIR)
        except IOError:
            log_message(f"ğŸ“ é ç«¯ç›®éŒ„ {SFTP_REMOTE_DIR} ä¸å­˜åœ¨ï¼Œæ­£åœ¨å‰µå»º...")
            sftp.mkdir(SFTP_REMOTE_DIR)
            sftp.chdir(SFTP_REMOTE_DIR)

        for file in os.listdir(output_dir):
            local_path = os.path.join(output_dir, file)
            remote_path = os.path.join(SFTP_REMOTE_DIR, file)
            if os.path.isfile(local_path):
                log_message(f"â¬†ï¸ ä¸Šå‚³ {local_path} â†’ {remote_path}")
                sftp.put(local_path, remote_path)

        sftp.close()
        transport.close()
        log_message("âœ… SFTP ä¸Šå‚³å®Œæˆï¼")

    except Exception as e:
        log_message(f"âŒ SFTP ä¸Šå‚³å¤±æ•—: {e}")

if __name__ == "__main__":
    log_message("ğŸš€ è…³æœ¬é–‹å§‹åŸ·è¡Œ")
    process_yt_info()
    upload_files()
    log_message("ğŸ è…³æœ¬åŸ·è¡Œå®Œæˆ")
