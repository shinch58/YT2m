import os
import logging
import subprocess
import paramiko
import time
import json
import requests
from urllib.parse import urlparse

# ===== å°ˆæ¡ˆè³‡æ–™å¤¾è·¯å¾‘ =====
script_dir = os.path.dirname(os.path.abspath(__file__))  # scripts ç›®éŒ„
root_dir = os.path.dirname(script_dir)  # å°ˆæ¡ˆæ ¹ç›®éŒ„

output_dir = os.path.join(root_dir, 'output')
log_dir = os.path.join(root_dir, 'log')
cookies_path = os.path.join(root_dir, 'cookies.txt')  # è‡¨æ™‚ cookies æª”æ¡ˆ

os.makedirs(output_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)

print(f"ğŸ“ å°ˆæ¡ˆæ ¹ç›®éŒ„: {root_dir}")
print(f"ğŸ“ è…³æœ¬ç›®éŒ„: {script_dir}")

# ===== æ—¥èªŒè¨­ç½® =====
logging.basicConfig(
    filename=os.path.join(log_dir, 'log.txt'),
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# ===== å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥é…ç½® =====
YOUTUBE_API_KEY = os.getenv('YT_API_KEY', '')
cookies_content = os.getenv('YT_COOKIES', '')

# å¯«å…¥è‡¨æ™‚ cookies.txtï¼ˆæ”¯æ´å¤šè¡Œï¼‰
if cookies_content:
    with open(cookies_path, 'w', encoding='utf-8') as f:
        f.write(cookies_content)
    print(f"âœ… å·²å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ Cookies: {cookies_path}")
else:
    print("âš ï¸ æœªæ‰¾åˆ° YT_COOKIES ç’°å¢ƒè®Šæ•¸")

SF_L = os.getenv('SF_L', '')
if not SF_L:
    print("âŒ ç¼ºå°‘ SF_L ç’°å¢ƒè®Šæ•¸ï¼Œè«‹åœ¨ GitHub Secrets è¨­å®š")
    logging.error("ç¼ºå°‘ SF_L ç’°å¢ƒè®Šæ•¸")
    exit(1)

parsed_url = urlparse(SF_L)
SFTP_HOST = parsed_url.hostname
SFTP_PORT = parsed_url.port or 22
SFTP_USER = parsed_url.username
SFTP_PASSWORD = parsed_url.password
SFTP_REMOTE_DIR = parsed_url.path or "/"

print(f"âœ… é…ç½®è¼‰å…¥å®Œæˆ (SFTP: {SFTP_HOST}:{SFTP_PORT})")

# ===== è§£æç­–ç•¥è¨­ç½® =====
USE_API_CHECK = False  # æ˜¯å¦ä½¿ç”¨ API æª¢æŸ¥
FORCE_PARSE = False  # å¼·åˆ¶è§£æ
SKIP_NON_LIVE = True  # è·³ééç›´æ’­å…§å®¹

# ===== åœ°å€ç¹éè¨­ç½® =====
PROXY = None
GEO_BYPASS = True
GEO_BYPASS_COUNTRY = "TW"
USE_EMBED_URL = True
IGNORE_IP_RANGE = True
USE_IPV6 = False

# ===== yt_info.txt è·¯å¾‘ =====
yt_info_path = os.path.join(root_dir, 'yt_info.txt')

# ===== å¾é »é“ URL æ‰¾åˆ°ç›´æ’­ URL =====
def find_live_url(channel_url):
    """å˜—è©¦å¾é »é“ URL æ‰¾åˆ°æ­£åœ¨ç›´æ’­çš„å½±ç‰‡ URL"""
    print(f"ğŸ” å˜—è©¦å¾é »é“æ‰¾åˆ°ç›´æ’­...")
    
    live_urls = []
    
    if '/channel/' in channel_url or '/@' in channel_url or '/c/' in channel_url:
        base_url = channel_url.rstrip('/')
        live_urls.append(f"{base_url}/live")
    
    if '/channel/' in channel_url:
        channel_id = channel_url.split('/channel/')[-1].split('/')[0]
        live_urls.append(f"https://www.youtube.com/channel/{channel_id}/streams")
    
    for test_url in live_urls:
        print(f"   æ¸¬è©¦: {test_url}")
        cmd = ["yt-dlp", "--dump-json", "--playlist-items", "1"]
        
        if os.path.exists(cookies_path):
            cmd.extend(["--cookies", cookies_path])
        
        cmd.append(test_url)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=20, check=True)
            info = json.loads(result.stdout)
            
            is_live = info.get('is_live', False)
            live_status = info.get('live_status', 'not_live')
            video_id = info.get('id', '')
            
            if is_live or live_status == 'is_live':
                live_video_url = f"https://www.youtube.com/watch?v={video_id}"
                print(f"   âœ… æ‰¾åˆ°ç›´æ’­: {live_video_url}")
                logging.info(f"æ‰¾åˆ°ç›´æ’­ URL: {channel_url} â†’ {live_video_url}")
                return live_video_url, True
            else:
                print(f"   âš ï¸ éç›´æ’­ç‹€æ…‹: {live_status}")
                
        except subprocess.TimeoutExpired:
            print(f"   â±ï¸ æª¢æŸ¥è¶…æ™‚")
        except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
            print(f"   âŒ æª¢æŸ¥å¤±æ•—")
    
    print(f"   â„¹ï¸ æœªæ‰¾åˆ°æ­£åœ¨ç›´æ’­çš„å½±ç‰‡")
    return channel_url, False

# ===== ä½¿ç”¨ YouTube API æª¢æŸ¥ç›´æ’­ç‹€æ…‹ =====
def check_live_with_api(youtube_url):
    """ä½¿ç”¨ YouTube Data API v3 æª¢æŸ¥é »é“æ˜¯å¦æ­£åœ¨ç›´æ’­"""
    if not USE_API_CHECK or not YOUTUBE_API_KEY:
        return True, youtube_url
        
    # extract_id_from_url å‡½æ•¸éœ€è‡ªè¡Œå¯¦ä½œæˆ–ç§»é™¤ï¼Œæ­¤è™•å‡è¨­å­˜åœ¨
    video_id = youtube_url.split('v=')[-1].split('&')[0] if 'v=' in youtube_url else ''
    id_type = 'video' if video_id else 'channel'
    
    try:
        if id_type == 'video':
            api_url = f"https://www.googleapis.com/youtube/v3/videos"
            params = {
                'part': 'snippet,liveStreamingDetails',
                'id': video_id,
                'key': YOUTUBE_API_KEY
            }
            response = requests.get(api_url, params=params, timeout=10)
            data = response.json()
            
            if 'items' in data and len(data['items']) > 0:
                item = data['items'][0]
                snippet = item.get('snippet', {})
                is_live = snippet.get('liveBroadcastContent') == 'live'
                
                if is_live:
                    print(f"âœ… API ç¢ºèªç‚ºç›´æ’­ä¸­")
                    logging.info(f"API ç¢ºèªç›´æ’­: {youtube_url}")
                    return True, youtube_url
                else:
                    print(f"âš ï¸ API é¡¯ç¤ºéç›´æ’­ç‹€æ…‹")
                    return False, youtube_url
        
        elif id_type == 'channel':
            api_url = f"https://www.googleapis.com/youtube/v3/search"
            params = {
                'part': 'snippet',
                'channelId': video_id,
                'eventType': 'live',
                'type': 'video',
                'key': YOUTUBE_API_KEY
            }
            response = requests.get(api_url, params=params, timeout=10)
            data = response.json()
            
            if 'items' in data and len(data['items']) > 0:
                live_video_id = data['items'][0]['id']['videoId']
                live_url = f"https://www.youtube.com/watch?v={live_video_id}"
                print(f"âœ… API æ‰¾åˆ°ç›´æ’­å½±ç‰‡: {live_video_id}")
                return True, live_url
                
    except Exception as e:
        print(f"âš ï¸ API è«‹æ±‚å¤±æ•—: {e}")
        logging.error(f"API è«‹æ±‚å¤±æ•—: {youtube_url} â†’ {e}")
    
    return True, youtube_url

# ===== ä½¿ç”¨ yt-dlp é©—è­‰ç›´æ’­ç‹€æ…‹ =====
def check_if_live_with_ytdlp(youtube_url):
    """ä½¿ç”¨ yt-dlp æª¢æŸ¥æ˜¯å¦ç‚ºç›´æ’­"""
    cmd = ["yt-dlp", "--dump-json", "--playlist-items", "1", "--no-warnings"]
    
    if os.path.exists(cookies_path):
        cmd.extend(["--cookies", cookies_path])
    
    if PROXY:
        cmd.extend(["--proxy", PROXY])
    
    if GEO_BYPASS:
        cmd.append("--geo-bypass")
        if GEO_BYPASS_COUNTRY:
            cmd.extend(["--geo-bypass-country", GEO_BYPASS_COUNTRY])
    
    cmd.append(youtube_url)
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
        info = json.loads(result.stdout)
        
        is_live = info.get('is_live', False)
        live_status = info.get('live_status', 'not_live')
        
        if is_live and live_status == 'is_live':
            print(f"   âœ… ç¢ºèªç‚ºç›´æ’­ä¸­")
            return True
        return False
            
    except Exception as e:
        print(f"   âŒ æª¢æŸ¥å¤±æ•—")
        return False

# ===== yt-dlp è§£æ m3u8 =====
def grab(youtube_url, max_retries=3):
    """ä½¿ç”¨ yt-dlp å–å¾—ç›´æ’­ m3u8 URL"""
    
    is_live, corrected_url = check_live_with_api(youtube_url)
    
    if not is_live and not FORCE_PARSE:
        if not check_if_live_with_ytdlp(youtube_url):
            logging.warning(f"è·³ééç›´æ’­ URL: {youtube_url}")
            return "https://raw.githubusercontent.com/jz168k/YT2m/main/assets/no_s.m3u8"
    
    youtube_url = corrected_url
    
    strategies = [
        {"name": "Android + Cookies", "args": ["--extractor-args", "youtube:player_client=android"], "use_cookies": True, "use_geo_bypass": True},
        {"name": "Android Embedded", "args": ["--extractor-args", "youtube:player_client=android_embedded"], "use_cookies": True, "use_geo_bypass": True},
        {"name": "iOS", "args": ["--extractor-args", "youtube:player_client=ios"], "use_cookies": True, "use_geo_bypass": True},
        {"name": "Web Embed", "args": ["--extractor-args", "youtube:player_client=web_embedded"], "use_cookies": True, "use_geo_bypass": True},
        {"name": "TV Client", "args": ["--extractor-args", "youtube:player_client=tv_embedded"], "use_cookies": True, "use_geo_bypass": True},
    ]
    
    for strategy in strategies:
        print(f"
ğŸ”§ ç­–ç•¥: {strategy['name']}")
        
        cmd = [
            "yt-dlp", "-f", "best[height<=720]/best", "-g",
            "--no-check-certificate"
        ]
        cmd.extend(strategy["args"])
        
        if strategy["use_cookies"] and os.path.exists(cookies_path):
            cmd.extend(["--cookies", cookies_path])
        
        if strategy.get("use_geo_bypass", False) and GEO_BYPASS:
            cmd.append("--geo-bypass")
            if GEO_BYPASS_COUNTRY:
                cmd.extend(["--geo-bypass-country", GEO_BYPASS_COUNTRY])
        
        if PROXY:
            cmd.extend(["--proxy", PROXY])
        
        cmd.append(youtube_url)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=45)
            m3u8_url = result.stdout.strip()
            
            if m3u8_url and ("googlevideo.com" in m3u8_url or "m3u8" in m3u8_url.lower()):
                print(f"   âœ… è§£ææˆåŠŸï¼")
                logging.info(f"ç­–ç•¥ {strategy['name']} æˆåŠŸ: {youtube_url}")
                return m3u8_url
                
        except Exception as e:
            print(f"   âŒ è§£æå¤±æ•—")
        
        time.sleep(2)
    
    logging.error(f"æ‰€æœ‰ç­–ç•¥å¤±æ•—: {youtube_url}")
    return "https://raw.githubusercontent.com/jz168k/YT2m/main/assets/no_s.m3u8"

# ===== è§£æ yt_info.txt =====
def process_yt_info():
    if not os.path.exists(yt_info_path):
        print(f"âŒ æœªæ‰¾åˆ° {yt_info_path}")
        return
        
    try:
        with open(yt_info_path, "r", encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip()]
        logging.info(f"è®€å– yt_info.txt æˆåŠŸï¼Œå…± {len(lines)} è¡Œ")

        i = 1
        entries = lines[2:]  # è·³éå‰å…©è¡Œ
        for j in range(0, len(entries), 2):
            if j + 1 >= len(entries):
                continue
            info_line = entries[j]
            youtube_url = entries[j + 1]
            channel_name = info_line.split("|")[0].strip() or f"Channel{i:02d}"

            print(f"
{'='*60}")
            print(f"ğŸ” è™•ç†é »é“ {i}: {channel_name}")
            print(f"ğŸ“º YouTube URL: {youtube_url}")
            
            m3u8_url = grab(youtube_url)

            # å„²å­˜ .m3u8
            output_m3u8 = os.path.join(output_dir, f"y{i:02d}.m3u8")
            with open(output_m3u8, "w", encoding="utf-8") as f:
                f.write(f"#EXTM3U
#EXT-X-STREAM-INF:BANDWIDTH=1280000
{m3u8_url}
")
            logging.info(f"ç”Ÿæˆ m3u8: {output_m3u8}")

            # å„²å­˜ .php
            output_php = os.path.join(output_dir, f"y{i:02d}.php")
            with open(output_php, "w", encoding="utf-8") as f:
                f.write(f"<?php
header('Location: {m3u8_url}');
?>")
            logging.info(f"ç”Ÿæˆ php: {output_php}")

            print(f"âœ… å®Œæˆ: y{i:02d}.m3u8 å’Œ y{i:02d}.php")
            i += 1
            time.sleep(3)

    except Exception as e:
        logging.error(f"è™•ç† yt_info.txt å¤±æ•—: {e}")
        print(f"âŒ è™•ç† yt_info.txt å¤±æ•—: {e}")

# ===== SFTP ä¸Šå‚³ =====
def upload_files():
    print("
" + "="*60)
    print("ğŸš€ å•Ÿå‹• SFTP ä¸Šå‚³...")
    print("="*60)
    try:
        transport = paramiko.Transport((SFTP_HOST, SFTP_PORT))
        transport.connect(username=SFTP_USER, password=SFTP_PASSWORD)
        sftp = paramiko.SFTPClient.from_transport(transport)
        print(f"âœ… SFTP é€£ç·šæˆåŠŸ: {SFTP_HOST}")

        try:
            sftp.chdir(SFTP_REMOTE_DIR)
        except IOError:
            print(f"ğŸ“ å‰µå»ºé ç«¯ç›®éŒ„: {SFTP_REMOTE_DIR}")
            sftp.mkdir(SFTP_REMOTE_DIR)
            sftp.chdir(SFTP_REMOTE_DIR)

        uploaded_count = 0
        for file in os.listdir(output_dir):
            local_path = os.path.join(output_dir, file)
            remote_path = os.path.join(SFTP_REMOTE_DIR, file)
            if os.path.isfile(local_path):
                print(f"â¬†ï¸ ä¸Šå‚³ {file}")
                sftp.put(local_path, remote_path)
                uploaded_count += 1

        sftp.close()
        transport.close()
        print(f"âœ… ä¸Šå‚³å®Œæˆï¼å…± {uploaded_count} å€‹æª”æ¡ˆ")
        logging.info(f"SFTP ä¸Šå‚³å®Œæˆï¼Œå…± {uploaded_count} å€‹æª”æ¡ˆ")
        
    except Exception as e:
        print(f"âŒ SFTP ä¸Šå‚³å¤±æ•—: {e}")
        logging.error(f"SFTP ä¸Šå‚³å¤±æ•—: {e}")

# ===== ä¸»ç¨‹å¼å…¥å£ =====
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¬ YouTube ç›´æ’­ M3U8 è§£æå™¨ (GitHub Actions ç‰ˆ)")
    print("="*60)
    
    # æª¢æŸ¥ yt-dlp
    try:
        result = subprocess.run(["yt-dlp", "--version"], capture_output=True, text=True)
        print(f"âœ… yt-dlp ç‰ˆæœ¬: {result.stdout.strip()}")
    except:
        print("âŒ æœªå®‰è£ yt-dlpï¼Œè«‹åœ¨ workflow å®‰è£")
        exit(1)
    
    print(f"ğŸ”‘ API Key: {'âœ…' if YOUTUBE_API_KEY else 'âŒ'}")
    print(f"ğŸª Cookies: {'âœ…' if os.path.exists(cookies_path) else 'âŒ'}")
    print(f"ğŸŒ SFTP: âœ…")
    
    start_time = time.time()
    
    process_yt_info()
    upload_files()
    
    elapsed_time = time.time() - start_time
    print(f"
â±ï¸ ç¸½åŸ·è¡Œæ™‚é–“: {elapsed_time:.2f} ç§’")
    logging.info(f"åŸ·è¡Œå®Œæˆï¼Œç¸½æ™‚é–“: {elapsed_time:.2f} ç§’")
